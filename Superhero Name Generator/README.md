# [1] Fine-Tune-BERT-for-Quora Insincere Questions Classification-with-TensorFlow

<div align="center">
    <img width="512px" src='images/superhero.png' />
    <p style="text-align: center;color:gray">Figure 1: BERT Classification Model</p>
</div>

In this guided project I have learnt -
- How to efficiently handle data and create input pipelines with td.data for bert models.
- Tokenize and Preprocess Text for BERT using bert tokenizer.
- Fine-tune BERT for text classification with TensorFlow 2 and TF Hub.

Some <b>useful resources</b> to learn about bert and transformers:

1. The Illustrated Transformer (Jay Alammar)[https://jalammar.github.io/illustrated-transformer/]

2. The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)[https://jalammar.github.io/illustrated-bert/]

3. The Annotated Transformer (Harvard NLP)[https://nlp.seas.harvard.edu/2018/04/03/attention.html]

4. For more advanced learners, here's the original BERT paper: (BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding)[https://arxiv.org/abs/1810.04805]
